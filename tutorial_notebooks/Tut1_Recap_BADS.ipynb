{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6b30d65",
   "metadata": {},
   "source": [
    "**Exercise predictive modeling:**<br>\n",
    "In this exercise, you recapitulate the principles of predictive modeling. You will build a predictive model for a travel \n",
    "insurance, which predicts whether a given insurance offer leads to a claim. You can use \"Ex03-Python_Machine_Learning.ipynb\" \n",
    "to lookup on the model building procedure and the required commands in python. \n",
    "\n",
    "In the next cells, we provide the code for importing required packages and for loading the data set (You need to adapt the\n",
    "path to the data.). Afterwards, the exercises begin.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d1f7d5-4c40-4655-a390-6524b5dfae2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Install the packages from the requirement.txt file:\n",
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e42767a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# required packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b33cc8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## read data\n",
    "path='travel insurance.csv'\n",
    "trav_ins = pd.read_csv(path,\n",
    "                       index_col=False,\n",
    "                       sep=',', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31ec2ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## get to know the data\n",
    "print('Shape of data: ',trav_ins.shape,'\\n')\n",
    "print('Head of data: \\n',trav_ins.head(10),'\\n')\n",
    "print('Descriptive statistics of data: \\n')\n",
    "print('Numerical columns: \\n',trav_ins.describe(include=np.number),'\\n')\n",
    "print('Categorical columns: \\n',trav_ins.describe(include=object),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9413e302-b11d-480f-b90a-16cae3034d2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove the rows where the feature Duration has negative values:\n",
    "trav_ins=trav_ins[trav_ins['Duration']>=0]\n",
    "#Get the number of duplicated rows and remove any duplicates after that:\n",
    "print('Number of duplicated samples: ',trav_ins[trav_ins.duplicated()].shape[0])\n",
    "trav_ins=trav_ins.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390291cd",
   "metadata": {},
   "source": [
    "**Exercise 1:**<br>\n",
    "Impute missing values with an approach of your own choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cc0679",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print('Overview missing values per feature: \\n',trav_ins.isna().sum())\n",
    "trav_ins['Gender']=trav_ins['Gender'].fillna('missing')\n",
    "plt.rcParams['figure.figsize']=5,3\n",
    "sns.countplot(x='Gender',data=trav_ins)\n",
    "plt.title('Category counts in variable Gender: ')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1c22c1",
   "metadata": {},
   "source": [
    "**Exercise 2:**<br>\n",
    "Appropriately encode the target \"Claim\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8986da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trav_ins['Claim']=trav_ins['Claim'].map({'No':0,'Yes':1})\n",
    "plt.rcParams['figure.figsize']=5,3\n",
    "sns.countplot(x='Claim',data=trav_ins)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6cd291",
   "metadata": {},
   "source": [
    "**Exercise 3:**<br>\n",
    "Appropriately encode the categorical variables. We recommend merging categories with few observations in one group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2137805",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_categorical_levels(grouping_criteria,data):\n",
    "    categorical_columns=data.select_dtypes(include=object).columns\n",
    "\n",
    "    for cat_col in categorical_columns:\n",
    "        category_counts=data[cat_col].value_counts()\n",
    "        print('Categorical column: ',cat_col)\n",
    "        print('Category counts before grouping: \\n',category_counts,'\\n')\n",
    "        data[cat_col]=np.where(data[cat_col].isin(category_counts[category_counts.lt(grouping_criteria)].index),'Other',data[cat_col])\n",
    "        if len(data[cat_col].value_counts().keys())!=len(category_counts.keys()):\n",
    "            print('Category counts after grouping: \\n',data[cat_col].value_counts(),'\\n\\n')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9335ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "trav_ins=group_categorical_levels(grouping_criteria=2000,\n",
    "                         data=trav_ins.copy())\n",
    "trav_ins=pd.get_dummies(data=trav_ins,\n",
    "                        prefix_sep='_',columns=trav_ins.select_dtypes(include=object).columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fbfc34",
   "metadata": {},
   "source": [
    "**Exercise 4:**<br>\n",
    "Split 80% of the data in the training set and the remaining 20% data in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870ad845",
   "metadata": {},
   "outputs": [],
   "source": [
    "#take the first 10000 samples in order to perform the tuning of RF faster:\n",
    "trav_ins_smaller=trav_ins.iloc[:10000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f965cc56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=train_test_split(trav_ins_smaller.drop(['Claim'],axis=1),#features\n",
    "                                                                  trav_ins_smaller['Claim'],#target\n",
    "                                                                  test_size=0.2,random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e900d40a",
   "metadata": {},
   "source": [
    "**Exercise 5:**<br>\n",
    "Build a random forest model on the training data. Find the best tuning parameters by grid search.  \n",
    "Below is a simple grid, which you could choose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca130dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define a hyperparameter grid for tuning the ML model:\n",
    "param_grid = {'n_estimators': [500,1000],\n",
    "              'max_features': [4, 8, 12],\n",
    "              'max_depth':[10,15]\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90779e27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Perform Grid Search Cross Validation with 5 folds:\n",
    "gs_rf=GridSearchCV(estimator=RandomForestClassifier(),\n",
    "                   param_grid=param_grid,\n",
    "                   cv=5,scoring='roc_auc',\n",
    "                   verbose=1)\n",
    "gs_rf.fit(X_train,y_train)\n",
    "\n",
    "print('Grid Search CV Results when grouping categorical levels with less than 2000 occurances: \\n')\n",
    "print('Best Score: ',gs_rf.best_score_)\n",
    "print('Best parameters: ',gs_rf.best_params_)\n",
    "rf_best=gs_rf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfaefa0",
   "metadata": {},
   "source": [
    "**Exercise 6:**<br>\n",
    "Evaluate the model by appropriate metrics on the test set. Is the model able to predict claims with certainty?\n",
    "Is the model usefull for application?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679a3044-b2f4-40cd-adba-9a4b72b82778",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, precision_score,roc_auc_score\n",
    "predicted_labels=rf_best.predict(X_test)\n",
    "predicted_probas=rf_best.predict_proba(X_test)\n",
    "predicted_probas=predicted_probas[:,1]\n",
    "print('Results on test dataset: \\n')\n",
    "print('Recall Score: ',round(recall_score(y_true=y_test,y_pred=predicted_labels),3))\n",
    "print('Precision Score: ',round(precision_score(y_true=y_test,y_pred=predicted_labels),3))\n",
    "print('AUC Score: ',round(roc_auc_score(y_true=y_test,y_score=predicted_probas),3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9769a8-af3f-42e7-86a1-8b40d9081026",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "adjusted_labels=np.where(predicted_probas>=predicted_probas.mean(),1.0,0.0)\n",
    "print('Prediction counts: ',np.unique(adjusted_labels,return_counts=True))\n",
    "print('Recall Score: ',round(recall_score(y_true=y_test,y_pred=adjusted_labels),3))\n",
    "print('Precision Score: ',round(precision_score(y_true=y_test,y_pred=adjusted_labels),3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f598a9-5b74-4cad-82eb-cf04d6e15e44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']=15,5\n",
    "ax1=plt.subplot(2,3,1)\n",
    "ax2=plt.subplot(2,3,2)\n",
    "\n",
    "#First Boxplot:\n",
    "true_positives_indices=np.where(y_test==1.0)[0]\n",
    "predicted_proba_TP=predicted_probas[true_positives_indices]\n",
    "ax1.boxplot(predicted_proba_TP)\n",
    "ax1.set_title('Predicted Probabilities \\n for True Positive Cases (Claim)')\n",
    "\n",
    "#Second Boxplot:\n",
    "true_negative_indices=np.where(y_test==0)[0]\n",
    "predicted_proba_TN=predicted_probas[true_negative_indices]\n",
    "ax2.boxplot(predicted_proba_TN)\n",
    "ax2.set_title('Predicted Probabilities \\n for True Negative Cases (no Claim)')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef922d8",
   "metadata": {},
   "source": [
    "**Bonus:**<br>\n",
    "Identify which features are most relevant in predicting claims and how they affect the predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226885d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## feature importance\n",
    "perm_imp=permutation_importance(estimator=rf_best,\n",
    "                                X=X_test,\n",
    "                                y=y_test,\n",
    "                                scoring='roc_auc',random_state=123)\n",
    "\n",
    "sorted_idx_features=perm_imp.importances_mean.argsort()\n",
    "\n",
    "plt.rcParams['figure.figsize']=30,10\n",
    "fig,ax=plt.subplots()\n",
    "ax.boxplot(perm_imp.importances[sorted_idx_features].T,\n",
    "          vert=False, \n",
    "          labels=X_test.columns[sorted_idx_features])\n",
    "fig.tight_layout()\n",
    "plt.title('Permutation importance per feature')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610f4ab8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## partial dependence plot\n",
    "plt.rcParams['figure.figsize']=30,10\n",
    "PartialDependenceDisplay.from_estimator(rf_best, \n",
    "                        X=X_test, \n",
    "                        features=['Net Sales'])\n",
    "plt.title('Partial Dependence Plot for the relationship between Claim (Target) and Net Sales (Predictor)')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6195831",
   "metadata": {},
   "source": [
    "Tune the grouping condition for the reduction of the number of categorical levels (as requested during the tutorial session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43762b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trav_ins = pd.read_csv(path,index_col=False,sep=',', encoding='utf-8')\n",
    "trav_ins=trav_ins[trav_ins['Duration']>=0]\n",
    "trav_ins=trav_ins.drop_duplicates(keep='first')\n",
    "trav_ins['Gender']=trav_ins['Gender'].fillna('missing')\n",
    "trav_ins['Claim']=trav_ins['Claim'].map({'No':0,'Yes':1})\n",
    "\n",
    "#Pick several values to be used for the grouping of the categorical levels: \n",
    "grouping_condition_list=[500,2000]\n",
    "\n",
    "#Build the loop in which you preprocess categorical features from your data, \n",
    "#split into train and test set, \n",
    "#and get cross validation results:\n",
    "for gr_ct in grouping_condition_list:\n",
    "    #Group the levels:\n",
    "    \n",
    "    print('\\033[1m','Grouping condition:','\\033[0m',' less than ',gr_ct,'occurances')\n",
    "    trav_ins_grouped=group_categorical_levels(grouping_criteria=gr_ct,\n",
    "                         data=trav_ins.copy())\n",
    "    \n",
    "    #Get dummy indicator variables:\n",
    "    trav_ins_grouped=pd.get_dummies(data=trav_ins_grouped,\n",
    "                        prefix_sep='_',columns=trav_ins_grouped.select_dtypes(include=object).columns)\n",
    "    print('Shape of dataset after grouping of categorical levels and creating dummy indicator variables: ',trav_ins_grouped.shape)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test=train_test_split(trav_ins_grouped.drop(['Claim'],axis=1),#features\n",
    "                                                      trav_ins_grouped['Claim'],#target\n",
    "                                                      test_size=0.2,random_state=5)\n",
    "    \n",
    "    #Perform Grid Search Cross Validation with 5 folds:\n",
    "    gs_rf=GridSearchCV(estimator=RandomForestClassifier(),\n",
    "                       param_grid=param_grid,\n",
    "                       cv=5,scoring='roc_auc',verbose=1)\n",
    "    gs_rf.fit(X_train,y_train)\n",
    "\n",
    "    print('Grid Search CV Results when grouping categorical levels with less than',gr_ct,' occurances: \\n')\n",
    "    print('Best Score: ',gs_rf.best_score_)\n",
    "    print('Best parameters: ',gs_rf.best_params_,'\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde15b13",
   "metadata": {},
   "source": [
    "Different ways of encoding categorical features for ML models: https://towardsdatascience.com/all-about-categorical-variable-encoding-305f3361fd02"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
