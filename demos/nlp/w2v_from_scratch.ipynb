{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XyuoS1V_A74Q",
    "tags": []
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Humboldt-WI/adams/blob/master/demos/nlp/w2v_from_scratch.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "skvR6YA3A74T"
   },
   "source": [
    "# Word-to-Vec from Scratch - UNDER CONSTRUCTION\n",
    "This notebook is the third demo on natural language processing and word embeddings. Having discovered the [fundamentals of NLP](https://github.com/Humboldt-WI/adams/blob/master/demos/nlp/nlp_foundations.ipynb) and how we can train [custom word embeddings using the Gensim library]https://github.com/Humboldt-WI/adams/blob/master/demos/nlp/word-2-vec.ipynb, the purpose of this demo is to illustrate a from scratch implementation of the W2V algorithm. \n",
    "\n",
    "Unfortunately, at the time of writing, updates of Keras and Tensorflow render our prepared code invalid and enforce a major revision. While we are working on this major revision, we would at least provide you with some links to useful resources.\n",
    "\n",
    "First, the new version of the demo we are preparing will draw heavily on the very good Word-to-Vec tutorial on [the Tensorflow homepage](https://www.tensorflow.org/tutorials/text/word2vec).\n",
    "\n",
    "Further, being a very popular algorithm, you can find many tutorials that walk you through a from scratch implementation of W2V using nothing but plain Python and Numpy. Here are some examples:\n",
    "- [Word2vec from Scratch with NumPy](https://towardsdatascience.com/word2vec-from-scratch-with-numpy-8786ddd49e72)\n",
    "-[Word2vec from Scratch](https://jaketae.github.io/study/word2vec/)\n",
    "-[Word2vec from Scratch with Python and NumPy](https://nathanrooy.github.io/posts/2018-03-22/word2vec-from-scratch-with-python-and-numpy/)\n",
    "\n",
    "\n",
    "Last, it goes without saying that excellent resources including various Python codes can be obtained from [Dive into Deep Learning](https://www.d2l.ai/), [Chapter 14](https://www.d2l.ai/chapter_natural-language-processing-applications/index.html).\n",
    "\n",
    "For the revised version of our ADAMS demo, stay tuned..."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "P.II.2_nlp_foundations.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
