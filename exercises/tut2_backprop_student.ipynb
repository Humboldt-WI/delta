{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd02e0c5",
   "metadata": {},
   "source": [
    "## Exercise Neural Network Training:\n",
    "The exercise is meant to build some understanding about how neural networks learn relationships between features x and a \n",
    "target y. The exercise deals with gradient descent. In this exercises we assume that students are familiar with the general form of neural networks. Hence, the architecture of neural networks is not part of the exercises. We recommend going through \"Ex04-NN-Primer-part1.ipynb\". It covers the architecture of neural networks as well as the learning procedure, which is part of this exercise.    \n",
    "\n",
    "\"Ex04-NN-Primer-part1.ipynb\" treats topics like gradient descent for neural networks of general architecture. For this exercise, we restrict the architecture of the considered neural networks to the form\n",
    "$f(x)=\\beta\\cdot sigmoid(x)$. This corresponds to a very simple neural network with linear output function, sigmoid activation, 1 hidden layer and bias (constants) forced to zero. By considering this simple neural network, the code becomes simpler and you can (hopefully) gain a better intuition of neural networks learning procedures.  \n",
    "\n",
    "In the tuturial to this exercise, we will go through further exercises covering back propagation and stochastic gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "27cd65ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "## required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "3b724d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define sigmoid function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "## create data\n",
    "x = np.array(range(-10,10))\n",
    "y = 2*sigmoid(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebc36f5",
   "metadata": {},
   "source": [
    "# Exercise:\n",
    "Our goal is to find the coefficient beta, such that the function $f(x)=\\beta\\cdot sigmoid(x)$ fits the data best \n",
    "(according to the mean squared error).  \n",
    "Your task is to implement gradient descent in order to find beta. This means in detail: <br />\n",
    "a) You need to calculate the derivative of the loss function $L(Y,f(X))=\\frac{1}{n}\\sum_{i}(y_{i}-f(x_{i}))^{2}$ in $\\beta$. For simplicity we provide an impementation\n",
    "of this loss function called \"grad_beta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "0d877efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_f(beta, x):\n",
    "    return beta*sigmoid(x)\n",
    "def grad_beta(beta, y, x): \n",
    "    return np.mean(-2*(y-func_f(beta, x))*sigmoid(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8fc3ac",
   "metadata": {},
   "source": [
    "b) Implement a function grad_desc(beta_ini, lrate, n_epochs), with an initial value of beta,\n",
    "the learning rate and the number of iterations (called epochs) as parameters. The function should find the $\\beta$ leading to the minimum loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2748e2f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e01de131",
   "metadata": {},
   "source": [
    "c) Apply your function for beta_ini=0, n_epochs=20 and some learning rates of your choice.\n",
    "Which is the best learning rate? What happens for particularly high or low learning rates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2725b759",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
